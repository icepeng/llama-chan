# LLaMA-chan

Speedy ChatGPT-style model on your local device.

Built on top of setzer22's [llama-rs](https://github.com/setzer22/llama-rs) and [tauri.app](https://tauri.app/).

![example image](example.gif)

## Getting Started

### Download executable

#### From release

Download `llama-chan-win.zip` from the latest release. Other platforms will be released soon.

#### Building from Source

1. Follow the [prerequisites](https://tauri.app/v1/guides/getting-started/prerequisites) from Tauri.
2. `yarn install` in shell.
3. `yarn tauri build` in shell.
4. builds are generated in `src-tauri/target/release/`.

### Download models

#### alpaca-lora 7B

```
# Any of these commands will work.
curl -o ggml-alpaca-7b-q4.bin -C - https://gateway.estuary.tech/gw/ipfs/QmQ1bf2BTnYxq73MFJWu1B7bQ2UD6qG7D7YDCxhTndVkPC
curl -o ggml-alpaca-7b-q4.bin -C - https://ipfs.io/ipfs/QmQ1bf2BTnYxq73MFJWu1B7bQ2UD6qG7D7YDCxhTndVkPC
curl -o ggml-alpaca-7b-q4.bin -C - https://cloudflare-ipfs.com/ipfs/QmQ1bf2BTnYxq73MFJWu1B7bQ2UD6qG7D7YDCxhTndVkPC

# BitTorrent
magnet:?xt=urn:btih:5aaceaec63b03e51a98f04fd5c42320b2a033010&dn=ggml-alpaca-7b-q4.bin&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Fopentracker.i2p.rocks%3A6969%2Fannounce
https://btcache.me/torrent/5AACEAEC63B03E51A98F04FD5C42320B2A033010
https://torrage.info/torrent.php?h=5aaceaec63b03e51a98f04fd5c42320b2a033010
```

#### alpaca-lora 13B

If you have more than 10GB of RAM, you can use the higher quality 13B ggml-alpaca-13b-q4.bin model. To download the weights, you can use

```
# Any of these commands will work.
curl -o ggml-alpaca-13b-q4.bin -C - https://gateway.estuary.tech/gw/ipfs/Qme6wyw9MzqbrUMpFNVq42rC1kSdko7MGT9CL7o1u9Cv9G
curl -o ggml-alpaca-13b-q4.bin -C - https://ipfs.io/ipfs/Qme6wyw9MzqbrUMpFNVq42rC1kSdko7MGT9CL7o1u9Cv9G
curl -o ggml-alpaca-13b-q4.bin -C - https://cloudflare-ipfs.com/ipfs/Qme6wyw9MzqbrUMpFNVq42rC1kSdko7MGT9CL7o1u9Cv9G

# BitTorrent
magnet:?xt=urn:btih:053b3d54d2e77ff020ebddf51dad681f2a651071&dn=ggml-alpaca-13b-q4.bin&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Fopentracker.i2p.rocks%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A6969%2Fannounce&tr=udp%3A%2F%2F9.rarbg.com%3A2810%2Fannounce
https://btcache.me/torrent/053B3D54D2E77FF020EBDDF51DAD681F2A651071
https://torrage.info/torrent.php?h=053b3d54d2e77ff020ebddf51dad681f2a651071
```

(Instructions are copied from [alpaca.cpp](https://github.com/antimatter15/alpaca.cpp))

## Disclaimer

Note that the model weights are only to be used for research purposes, as they are derivative of LLaMA, and uses the published instruction data from the Stanford Alpaca project which is generated by OpenAI, which itself disallows the usage of its outputs to train competing models.
